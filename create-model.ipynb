{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7939  rows\n",
      "5  cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropperc</th>\n",
       "      <th>mins</th>\n",
       "      <th>consecmonths</th>\n",
       "      <th>income</th>\n",
       "      <th>churn_Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>844336</th>\n",
       "      <td>0.016364</td>\n",
       "      <td>550</td>\n",
       "      <td>28</td>\n",
       "      <td>89.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146041</th>\n",
       "      <td>0.018349</td>\n",
       "      <td>545</td>\n",
       "      <td>33</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847745</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>378</td>\n",
       "      <td>41</td>\n",
       "      <td>55.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285565</th>\n",
       "      <td>0.014493</td>\n",
       "      <td>552</td>\n",
       "      <td>32</td>\n",
       "      <td>66.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754611</th>\n",
       "      <td>0.012132</td>\n",
       "      <td>577</td>\n",
       "      <td>4</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dropperc  mins  consecmonths  income  churn_Y\n",
       "custid                                               \n",
       "844336  0.016364   550            28    89.2        0\n",
       "146041  0.018349   545            33    54.2        0\n",
       "847745  0.018519   378            41    55.3        0\n",
       "285565  0.014493   552            32    66.8        0\n",
       "754611  0.012132   577             4    87.2        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFile = os.path.join(\n",
    "    os.environ[\"PWD\"],\n",
    "    \"data\",\n",
    "    \"smallPrepared.csv\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(dataFile, header=0, index_col=0)\n",
    "print(len(df), \" rows\")\n",
    "print(len(df.columns), \" cols\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "columns.remove('churn_Y')\n",
    "y = df[\"churn_Y\"].values\n",
    "X = df[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ad1 = AdaBoostClassifier(learning_rate=1)\n",
    "ad1 = ad1.fit(X, y)\n",
    "ad1prb = ad1.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ad2 = AdaBoostClassifier(learning_rate=0.5)\n",
    "ad2 = ad2.fit(X, y)\n",
    "ad2prb = ad2.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb1 = GradientBoostingClassifier(loss = 'exponential', max_depth=3)\n",
    "gb1 = gb1.fit(X, y)\n",
    "gb1prb = gb1.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb2 = GradientBoostingClassifier(loss = 'exponential', max_depth=10)\n",
    "gb2 = gb2.fit(X, y)\n",
    "gb2prb = gb2.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf1 = RandomForestClassifier(max_depth=None)\n",
    "rf1 = rf1.fit(X, y)\n",
    "rf1prb = rf1.predict_proba(X)\n",
    "rf1pclass = rf1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf2 = RandomForestClassifier(max_depth = 5)\n",
    "rf2 = rf2.fit(X, y)\n",
    "rf2prb = rf2.predict_proba(X)\n",
    "rf2pclass = rf2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf3 = RandomForestClassifier(max_depth = 30)\n",
    "rf3 = rf3.fit(X, y)\n",
    "rf3prb = rf3.predict_proba(X)\n",
    "rf3pclass = rf3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg = logreg.fit(X, y)\n",
    "logregprb = logreg.predict_proba(X)\n",
    "logregpclass = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.61171836]\n",
      "[[ 0.40323489 -0.0090457   0.09232167  0.01609967]]\n"
     ]
    }
   ],
   "source": [
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Cross Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e984f8aca9ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# takes a list of models, the input np.array, the target np.array, the type of score to be used with cv, and k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# each element in the list of models should have two items: the model object and the name you want to use for that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cross_validation'"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "# takes a list of models, the input np.array, the target np.array, the type of score to be used with cv, and k\n",
    "# each element in the list of models should have two items: the model object and the name you want to use for that \n",
    "# model object\n",
    "# returns a dataframe with the names you entered and the mean of the cv scores across all k folds\n",
    "\n",
    "def cv_fun(models, inputs, target, score, k):\n",
    "    i = 0\n",
    "    for m in models:\n",
    "        scores = cross_validation.cross_val_score(models[i][0], inputs, target, scoring=score, cv=k)\n",
    "    \n",
    "        if i==0:\n",
    "            list1 = list()\n",
    "            list2 = list()\n",
    "            \n",
    "        list1.append(round(scores.mean(),3))\n",
    "        list2.append(models[i][1])\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    return pd.DataFrame(list1, index=list2, columns=[score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation on the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the cv function found up under the Setup section\n",
    "# enter a list with each entry holding the model object followed by a text name you want to give the model\n",
    "\n",
    "input_models = [[ad1, 'ad1']]\n",
    "input_models.append([ad2, 'ad2'])\n",
    "input_models.append([gb1, 'gb1'])\n",
    "input_models.append([gb2, 'gb2'])\n",
    "input_models.append([rf1, 'rf1'])\n",
    "input_models.append([rf2, 'rf2'])\n",
    "input_models.append([rf3, 'rf3'])\n",
    "input_models.append([logreg, 'logreg'])\n",
    "\n",
    "cv_auc = cv_fun(input_models, X, y, 'roc_auc', 5)\n",
    "cv_acc = cv_fun(input_models, X, y, 'accuracy', 5)\n",
    "cv_results = cv_auc.join(cv_acc)\n",
    "cv_results.sort_values(by='roc_auc', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually pick best, would be nice to automate this part\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "best = gb1\n",
    "pickle.dump(best, open('/mnt/results/smallModel.pkl', 'wb')) # w = open for writing, r = open for reading, b = binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make confusion matrix plot\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    " \n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    " \n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    " \n",
    "    title:        the text to display at the top of the matrix\n",
    " \n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    " \n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    " \n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    " \n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    " \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    " \n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    " \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    " \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    " \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    " \n",
    " \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.gcf().subplots_adjust(bottom=0.25)\n",
    "    plt.savefig('/mnt/results/ConfMatx_Best.png', format='png')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "plot_confusion_matrix(cm           = metrics.confusion_matrix(y, best.predict(X)), \n",
    "                      normalize    = False,\n",
    "                      target_names = ['no churn', 'churn'],\n",
    "                      title        = \"Confusion Matrix for Best Model\")\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2[\"prob\"] = best.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('/mnt/data/smallModelOut.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
